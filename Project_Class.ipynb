{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dc404d-f717-49e5-ba92-4e1950d8ad1c",
   "metadata": {},
   "source": [
    "# Classification Model Tuning Project  \n",
    "\n",
    "## Project Overview  \n",
    "This project focuses on **tuning the best model for classification** based on a given dataset. The dataset consists of the following features:  \n",
    "\n",
    "- **Salary** (Numerical)  \n",
    "- **Age** (Numerical)  \n",
    "- **Sex** (Categorical)  \n",
    "\n",
    "The target variable (**Label**) is:  \n",
    "- **Purchased** (Binary: `0` - Not Purchased, `1` - Purchased)  \n",
    "\n",
    "The primary goal is to **research different classification models**, apply **hyperparameter tuning**, and evaluate their performance to determine the most effective approach.  \n",
    "\n",
    "##  Models Explored  \n",
    "To achieve the objective, the following classification models will be analyzed:  \n",
    "- **Logistic Regression**  \n",
    "- **K-Nearest Neighbors (KNN)**  \n",
    "- **Na√Øve Bayes**  \n",
    "\n",
    "Each model will undergo **hyperparameter tuning** to enhance its predictive accuracy and efficiency.  \n",
    "\n",
    "##  Key Objectives  \n",
    " Explore and preprocess the dataset  \n",
    " Train different classification models  \n",
    " Tune hyperparameters for each model  \n",
    " Compare model performance based on key metrics  \n",
    "\n",
    "##  Tools & Libraries  \n",
    "- Python  \n",
    "- Jupyter Notebook  \n",
    "- Scikit-learn (`sklearn`)  \n",
    "- Pandas  \n",
    "- NumPy  \n",
    "\n",
    "##  Learning Outcome  \n",
    "This project serves as a hands-on approach to **reinforcing theoretical knowledge** by practically implementing machine learning techniques, tuning models, and analyzing classification performance.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3f6a2-b196-44d5-99a2-20dc35ae4d9f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a1537-c7ee-4c55-a8d2-16f71ff12498",
   "metadata": {},
   "source": [
    "#### Let's begin with importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38a519a-3cdf-4d0c-ba0b-ee3648dd955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-Learn Imports\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             mean_squared_error, mean_absolute_error, r2_score)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15373061-de12-4451-90ff-ae242f121ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Social_Network_Ads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ab5a424-dad0-4ca2-b3de-2acb555d2433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d4bb0-1c4d-43f9-b514-b28e8f49332d",
   "metadata": {},
   "source": [
    "Now we need to preprocess the data. Checking if the dataset contains empty entries, reducing the UserID field, using one-hot encoding for the sex field and scaling age and salary fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22c07281-f108-49c5-bb9d-86880e2f1638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID            0\n",
      "Gender             0\n",
      "Age                0\n",
      "EstimatedSalary    0\n",
      "Purchased          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "#We see, that dataset is fine. It has no empty values. \n",
    "#In the opposite case we would handle the miising data in the following way:\n",
    "#Gender -> most frequent gender: data['Gender'] = data.fillna(data['Gender']. value_counts(). index[0])\n",
    "#age field -> median value: data['Age'] = data.fillna(data['Age'].median())\n",
    "#salary -> mean value: data['EstimatedSalary'] = data.fillna(data['EstimatedSalary'].median())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dedf5cc0-e827-4516-b95e-f2951e6bf196",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = ['User ID'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c836404-a9ff-4e16-9b74-924cdea1d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output = False, handle_unknown = 'ignore')\n",
    "encoded_arr = encoder.fit_transform(data[['Gender']])\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "encoded_df = pd.DataFrame(encoded_arr, columns = feature_names)\n",
    "data = pd.concat([data.drop(columns=['Gender']), encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d0ce779-981a-4c35-a7be-3f1c9e0dc48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(columns=['Purchased']),\n",
    "    data['Purchased'],\n",
    "    test_size=0.2,\n",
    "    random_state = 42,\n",
    "    stratify = data['Purchased'] #Making sure that train and test data has equal percentage of purchases\n",
    ")\n",
    "    \n",
    "#Now we need to apply the feature scaling\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f311cbb9-9e40-462e-921f-71411d75599e",
   "metadata": {},
   "source": [
    "Let's now consider different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11a764b3-e744-4239-ab14-1e68f98607cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "parameters_grid = {\n",
    "    'C' : [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    'solver' : ['saga', 'liblinear'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "reg = LogisticRegression(max_iter = 1000)\n",
    "grid_search = GridSearchCV(reg, parameters_grid, cv = 8, n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_logi_reg = grid_search.best_estimator_\n",
    "y_pred_logi_reg = best_logi_reg.predict(X_test)\n",
    "\n",
    "#K Nearest Neighbours\n",
    "parameters_grid = {\n",
    "    'n_neighbors': np.arange(2, 10, 1),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'], \n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search_knn = GridSearchCV(knn, parameters_grid, cv = 8, n_jobs = -1)\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "best_knn = grid_search_knn.best_estimator_\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "\n",
    "\n",
    "#Naive Gaussian Bayes\n",
    "gauss_nb = GaussianNB()\n",
    "gauss_nb.fit(X_train, y_train)\n",
    "y_pred_gauss = gauss_nb.predict(X_test)\n",
    "\n",
    "metrics = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_logi_reg),\n",
    "        \"precision\": precision_score(y_test, y_pred_logi_reg, average=\"weighted\"),\n",
    "        \"recall\": recall_score(y_test, y_pred_logi_reg, average=\"weighted\"),\n",
    "        \"f1_score\": f1_score(y_test, y_pred_logi_reg, average=\"weighted\"),\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_knn),\n",
    "        \"precision\": precision_score(y_test, y_pred_knn, average=\"weighted\"),\n",
    "        \"recall\": recall_score(y_test, y_pred_knn, average=\"weighted\"),\n",
    "        \"f1_score\": f1_score(y_test, y_pred_knn, average=\"weighted\"),\n",
    "    },\n",
    "    \"Naive Bayes\": {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_gauss),\n",
    "        \"precision\": precision_score(y_test, y_pred_gauss, average=\"weighted\"),\n",
    "        \"recall\": recall_score(y_test, y_pred_gauss, average=\"weighted\"),\n",
    "        \"f1_score\": f1_score(y_test, y_pred_gauss, average=\"weighted\"),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0f7cf30-2452-4986-9509-da85fcad005e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'accuracy': 0.775,\n",
       "  'precision': 0.7842436974789916,\n",
       "  'recall': 0.775,\n",
       "  'f1_score': 0.7574942791762014},\n",
       " 'KNN': {'accuracy': 0.7375,\n",
       "  'precision': 0.7347894265232975,\n",
       "  'recall': 0.7375,\n",
       "  'f1_score': 0.7195584635661835},\n",
       " 'Naive Bayes': {'accuracy': 0.875,\n",
       "  'precision': 0.8741264849755416,\n",
       "  'recall': 0.875,\n",
       "  'f1_score': 0.8739697802197803}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664fe864-72ad-4216-89e8-76d6a31deabb",
   "metadata": {},
   "source": [
    "So we can conclude that K nearest neighbours is the most ortimal model for solving the following task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e3c67-5a34-4d51-b71d-5428355c7697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
